\chapter{Conclusion} \label{Conclusion}
In this thesis, an overview is given of natural language processing w.r.t deep learning and text classification, and a dataset of medical reports was preprocessed and used to train a number of text classifiers in order to define the feasibility of such methods for medical text classification.

The results show that even though transformers have been shown to work for pretty much any task, YAYDAYDYA ---
Additionally, the performance of fastText proved to be surprising good when compared to the more complex and training intensive deep neural networks.

For future work, it is suggested that a larger general corpus of medical text is gathered and used to pre-train a deep neural network first in order to improve performance of the various methods such as transformer-based BERT and ELECTRA.
