\chapter{Introduction} \label{Introduction}
The automated text classification task dates back to the early '60s but became a major subfield of information systems only in the early '90s due to increased applicative interest and availability of more powerful hardware.
Until the late '80s the most common approach to text classification in real-world applications was a \textit{knowledge engineering} one, which consisted of manually defining a set of rules on how to best classify documents to given categories.
In the '90s this approach was passed in popularity by the \textit{machine learning} paradigm, according to which an automatic text classifier is built by a general inductive process automatically, by learning from a labelled dataset the characteristics of the categories \cite{sebastiani2002}.

Nowadays, huge deep neural networks dominate the field of automatic text classification. Even though they post the best results, other methods exist as well and have been used for a long time.



Chapter 2 gives a definition of text classification, insight on some of the most influential classifiers in the field of text classification in the past and a quick overview of neural networks as well.
Chapter 3 outlines the current state of machine learning -based natural language processing by explaining the different parts of a machine learning pipeline such as preprocessing, training and finetuning, and relevant model architectures.
Chapter 4 describes the medical report classification problem, the available data and compute resources and chosen methods, and discusses the results gained from utilizing said methods.
Chapter 5 is a concluding chapter which gives an overview of the thesis and its results.
